# Copilot Prompt Library Catalog

> **Auto-generated** by `render_catalog.py`.
> Do not edit this file directly. Update `prompts.json` and re-run the renderer.

This catalog contains **12 pre-built Copilot prompts** for automating
common Synapse-to-Fabric migration code fixes. Each prompt is designed to be
copy-pasted into GitHub Copilot Chat, Azure Data Studio Copilot, or any
LLM-powered coding assistant.

---

## Summary Statistics

| Metric | Value |
|--------|-------|
| Total prompts | 12 |
| Category: DDL Compatibility | 4 |
| Category: Data Type | 2 |
| Category: External Data | 1 |
| Category: Index Management | 1 |
| Category: Performance | 1 |
| Category: Query Compatibility | 1 |
| Category: Resource Management | 1 |
| Category: View Conversion | 1 |
| Severity: ðŸ”´ Critical | 2 |
| Severity: ðŸŸ  High | 4 |
| Severity: ðŸŸ¡ Medium | 4 |
| Severity: ðŸŸ¢ Low | 2 |
| Frequency: â¬› Very High | 1 |
| Frequency: ðŸ”· High | 5 |
| Frequency: ðŸ”¶ Medium | 3 |
| Frequency: ðŸ”¹ Low | 3 |

---

## Table of Contents

- [DIST-001: Distribution Hint Removal](#dist001) â€” ðŸŸ  High
- [CCI-001: Clustered Columnstore Index Removal](#cci001) â€” ðŸŸ¡ Medium
- [IDENT-001: IDENTITY Column Conversion](#ident001) â€” ðŸŸ  High
- [MATVIEW-001: Materialized View Conversion](#matview001) â€” ðŸŸ  High
- [EXTBL-001: External Table Conversion](#extbl001) â€” ðŸ”´ Critical
- [CTAS-001: CTAS Statement Conversion](#ctas001) â€” ðŸŸ¡ Medium
- [WLM-001: Workload Management Removal](#wlm001) â€” ðŸŸ¢ Low
- [XDBREF-001: Cross-Database Reference Resolution](#xdbref001) â€” ðŸ”´ Critical
- [UNICODE-001: Unicode String Normalization](#unicode001) â€” ðŸŸ¡ Medium
- [DTYPE-001: Deprecated Data Type Replacement](#dtype001) â€” ðŸŸ¡ Medium
- [PART-001: Partition Scheme Conversion](#part001) â€” ðŸŸ  High
- [STATS-001: Statistics Creation Syntax Update](#stats001) â€” ðŸŸ¢ Low

---

## DIST-001: Distribution Hint Removal

**Category:** DDL Compatibility
**Severity:** ðŸŸ  High
**Frequency:** â¬› Very High
**Tags:** `distribution` `hash` `replicate` `round-robin` `CREATE TABLE` `DDL` `WITH clause`

### Description

Azure Synapse dedicated SQL pools use DISTRIBUTION = HASH, REPLICATE, or ROUND_ROBIN clauses in CREATE TABLE statements to control physical data distribution across compute nodes. Microsoft Fabric Warehouse handles distribution automatically and does not support these hints. All distribution clauses must be removed for successful deployment to Fabric.

### When to Use

Apply this prompt whenever the assessment processor flags CREATE TABLE statements containing WITH (DISTRIBUTION = ...) clauses. This is one of the most common migration issues and should be addressed in the earliest migration sprints as it blocks table creation entirely.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following CREATE TABLE statement from an Azure Synapse dedicated SQL pool. Remove the DISTRIBUTION clause (HASH, REPLICATE, or ROUND_ROBIN) from the WITH block. If the WITH block becomes empty after removing the distribution clause, remove the entire WITH block. Preserve all column definitions, constraints, and other table properties. Do not change column names, data types, or NULL/NOT NULL specifications. Return only the cleaned SQL.
```

### Example

**Before** (Synapse):

```sql
CREATE TABLE [dbo].[FactSales]
(
    [SalesKey]        BIGINT         NOT NULL,
    [OrderDateKey]    INT            NOT NULL,
    [CustomerKey]     INT            NOT NULL,
    [ProductKey]      INT            NOT NULL,
    [Quantity]        INT            NOT NULL,
    [UnitPrice]       DECIMAL(18,2)  NOT NULL,
    [TotalAmount]     DECIMAL(18,2)  NOT NULL
)
WITH
(
    DISTRIBUTION = HASH([SalesKey]),
    CLUSTERED COLUMNSTORE INDEX
);
```

**After** (Fabric):

```sql
CREATE TABLE [dbo].[FactSales]
(
    [SalesKey]        BIGINT         NOT NULL,
    [OrderDateKey]    INT            NOT NULL,
    [CustomerKey]     INT            NOT NULL,
    [ProductKey]      INT            NOT NULL,
    [Quantity]        INT            NOT NULL,
    [UnitPrice]       DECIMAL(18,2)  NOT NULL,
    [TotalAmount]     DECIMAL(18,2)  NOT NULL
);
```

### Expected Outcome

The CREATE TABLE statement deploys successfully in Fabric Warehouse without distribution errors. Fabric automatically manages data distribution using its own internal optimization engine, so no manual distribution strategy is required.

### Related Prompts

[CCI-001](#cci001), [CTAS-001](#ctas001), [PART-001](#part001)

---

## CCI-001: Clustered Columnstore Index Removal

**Category:** Index Management
**Severity:** ðŸŸ¡ Medium
**Frequency:** ðŸ”· High
**Tags:** `CCI` `columnstore` `index` `CREATE TABLE` `DDL` `WITH clause` `storage`

### Description

Azure Synapse allows explicit declaration of CLUSTERED COLUMNSTORE INDEX in the WITH block of CREATE TABLE statements. In Microsoft Fabric Warehouse, clustered columnstore index is the default and only storage format for tables, so explicit CCI declarations are redundant and can cause deployment errors when combined with other WITH options.

### When to Use

Apply when assessment results show CREATE TABLE statements with explicit CLUSTERED COLUMNSTORE INDEX in the WITH clause. Often found alongside distribution hints, so this prompt is commonly used in conjunction with DIST-001.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following CREATE TABLE statement from an Azure Synapse dedicated SQL pool. Remove the CLUSTERED COLUMNSTORE INDEX clause from the WITH block. If the WITH block becomes empty after this removal, remove the entire WITH block including the WITH keyword. Fabric Warehouse uses clustered columnstore by default, so no explicit index declaration is needed. Preserve all column definitions, data types, and constraints exactly as they are. Return only the cleaned SQL.
```

### Example

**Before** (Synapse):

```sql
CREATE TABLE [dbo].[DimCustomer]
(
    [CustomerKey]     INT            NOT NULL,
    [CustomerName]    NVARCHAR(200)  NOT NULL,
    [Email]           NVARCHAR(256)  NULL,
    [Region]          NVARCHAR(50)   NOT NULL,
    [CreatedDate]     DATETIME2      NOT NULL
)
WITH
(
    DISTRIBUTION = REPLICATE,
    CLUSTERED COLUMNSTORE INDEX
);
```

**After** (Fabric):

```sql
CREATE TABLE [dbo].[DimCustomer]
(
    [CustomerKey]     INT            NOT NULL,
    [CustomerName]    NVARCHAR(200)  NOT NULL,
    [Email]           NVARCHAR(256)  NULL,
    [Region]          NVARCHAR(50)   NOT NULL,
    [CreatedDate]     DATETIME2      NOT NULL
);
```

### Expected Outcome

The CREATE TABLE statement deploys successfully in Fabric Warehouse. Tables are automatically stored using clustered columnstore format, providing optimal compression and query performance without explicit index declarations.

### Related Prompts

[DIST-001](#dist001), [CTAS-001](#ctas001)

---

## IDENT-001: IDENTITY Column Conversion

**Category:** DDL Compatibility
**Severity:** ðŸŸ  High
**Frequency:** ðŸ”· High
**Tags:** `IDENTITY` `surrogate key` `auto-increment` `DDL` `ETL` `ROW_NUMBER` `dimension table`

### Description

Azure Synapse dedicated SQL pools support IDENTITY(seed, increment) columns for auto-incrementing surrogate keys. Microsoft Fabric Warehouse does not currently support the IDENTITY property on columns. Workarounds include using ROW_NUMBER() window functions during data load, pre-computing surrogate keys in the ETL pipeline, or leveraging Fabric notebook-based sequence generation.

### When to Use

Apply when the assessment processor identifies columns with IDENTITY(1,1) or similar IDENTITY specifications. This is especially common in dimension tables where surrogate keys are generated. Address this early in migration because it affects both DDL and the associated ETL/INSERT logic.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following CREATE TABLE statement from an Azure Synapse dedicated SQL pool that contains an IDENTITY column. Remove the IDENTITY(seed, increment) property from the column definition. Add a comment indicating that surrogate key generation must be handled in the ETL pipeline using ROW_NUMBER() or a Fabric notebook sequence. Keep the column data type as-is (typically BIGINT or INT). If the table has an INSERT statement that relies on auto-generated identity values, note that the INSERT must be modified to explicitly provide key values. Return the cleaned DDL and any advisory comments.
```

### Example

**Before** (Synapse):

```sql
CREATE TABLE [dbo].[DimProduct]
(
    [ProductKey]      BIGINT         IDENTITY(1,1) NOT NULL,
    [ProductName]     NVARCHAR(200)  NOT NULL,
    [Category]        NVARCHAR(100)  NOT NULL,
    [SubCategory]     NVARCHAR(100)  NULL,
    [ListPrice]       DECIMAL(18,2)  NOT NULL,
    [IsActive]        BIT            NOT NULL DEFAULT 1
)
WITH
(
    DISTRIBUTION = REPLICATE
);
```

**After** (Fabric):

```sql
-- NOTE: IDENTITY column removed. Surrogate key generation must be handled
-- in the ETL pipeline using ROW_NUMBER() or a Fabric notebook sequence.
CREATE TABLE [dbo].[DimProduct]
(
    [ProductKey]      BIGINT         NOT NULL,
    [ProductName]     NVARCHAR(200)  NOT NULL,
    [Category]        NVARCHAR(100)  NOT NULL,
    [SubCategory]     NVARCHAR(100)  NULL,
    [ListPrice]       DECIMAL(18,2)  NOT NULL,
    [IsActive]        BIT            NOT NULL DEFAULT 1
);
```

### Expected Outcome

The CREATE TABLE statement deploys successfully in Fabric Warehouse without IDENTITY errors. The development team receives clear guidance on implementing surrogate key generation in the data pipeline layer, ensuring no gaps in key sequences during data loading.

### Related Prompts

[DIST-001](#dist001), [DTYPE-001](#dtype001)

---

## MATVIEW-001: Materialized View Conversion

**Category:** View Conversion
**Severity:** ðŸŸ  High
**Frequency:** ðŸ”¶ Medium
**Tags:** `materialized view` `view` `aggregation` `GROUP BY` `DDL` `performance` `Data Pipeline`

### Description

Azure Synapse supports CREATE MATERIALIZED VIEW with distribution and aggregation options for query acceleration. Microsoft Fabric Warehouse does not support materialized views. These must be converted to either standard views (for simple projections) or pre-computed tables populated by scheduled pipelines (for aggregation-heavy patterns that need materialization for performance).

### When to Use

Apply when the assessment processor identifies CREATE MATERIALIZED VIEW statements. Evaluate each materialized view individually: simple projections can become standard views, while complex aggregations that serve dashboards or reports may need to become pre-computed staging tables refreshed on a schedule via Fabric Data Pipelines or notebooks.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following CREATE MATERIALIZED VIEW statement from an Azure Synapse dedicated SQL pool. Convert it to a standard CREATE VIEW by removing the MATERIALIZED keyword and any WITH (DISTRIBUTION = ...) clause. If the view contains aggregations (GROUP BY, SUM, COUNT, AVG, etc.), add a comment recommending that a pre-computed table with scheduled refresh may provide better performance than a standard view. Preserve the SELECT logic exactly as written. Return the converted SQL with any advisory comments about performance considerations.
```

### Example

**Before** (Synapse):

```sql
CREATE MATERIALIZED VIEW [dbo].[mvw_DailySalesSummary]
WITH
(
    DISTRIBUTION = HASH([OrderDateKey])
)
AS
SELECT
    [OrderDateKey],
    [ProductKey],
    COUNT_BIG(*)          AS [SalesCount],
    SUM([TotalAmount])    AS [TotalRevenue],
    AVG([UnitPrice])      AS [AvgPrice]
FROM [dbo].[FactSales]
GROUP BY [OrderDateKey], [ProductKey];
```

**After** (Fabric):

```sql
-- NOTE: Converted from MATERIALIZED VIEW. This view contains aggregations.
-- For optimal performance, consider creating a pre-computed table refreshed
-- on a schedule via Fabric Data Pipeline or notebook instead of a standard view.
CREATE VIEW [dbo].[vw_DailySalesSummary]
AS
SELECT
    [OrderDateKey],
    [ProductKey],
    COUNT_BIG(*)          AS [SalesCount],
    SUM([TotalAmount])    AS [TotalRevenue],
    AVG([UnitPrice])      AS [AvgPrice]
FROM [dbo].[FactSales]
GROUP BY [OrderDateKey], [ProductKey];
```

### Expected Outcome

The materialized view is converted to a standard view that deploys in Fabric Warehouse. The development team receives guidance on performance optimization through pre-computed tables when aggregation-heavy views are critical for dashboard or reporting workloads.

### Related Prompts

[DIST-001](#dist001), [STATS-001](#stats001)

---

## EXTBL-001: External Table Conversion

**Category:** External Data
**Severity:** ðŸ”´ Critical
**Frequency:** ðŸ”· High
**Tags:** `external table` `PolyBase` `ADLS` `Lakehouse` `shortcut` `OPENROWSET` `OneLake` `Parquet`

### Description

Azure Synapse dedicated SQL pools use PolyBase external tables with CREATE EXTERNAL DATA SOURCE, CREATE EXTERNAL FILE FORMAT, and CREATE EXTERNAL TABLE to query data in Azure Data Lake Storage. Microsoft Fabric replaces this pattern with Lakehouse shortcuts and the OPENROWSET function for ad-hoc queries against files in OneLake. All PolyBase-related objects must be converted to the Fabric-native approach.

### When to Use

Apply when the assessment processor identifies CREATE EXTERNAL TABLE, CREATE EXTERNAL DATA SOURCE, or CREATE EXTERNAL FILE FORMAT statements. This is a critical conversion that affects the entire external data access layer. Coordinate with the Lakehouse setup team to ensure shortcuts are configured before converting dependent queries.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following external table definition from an Azure Synapse dedicated SQL pool that uses PolyBase. Convert it to a Fabric-compatible approach. Replace the CREATE EXTERNAL DATA SOURCE and CREATE EXTERNAL FILE FORMAT definitions with a comment noting that these are replaced by Lakehouse shortcuts in Fabric. Convert the CREATE EXTERNAL TABLE to either: (a) a reference to a Lakehouse shortcut table if the data should be permanently accessible, or (b) an OPENROWSET query if the access is ad-hoc. Preserve the column definitions and data types. Add comments explaining the Fabric Lakehouse shortcut setup steps. Return the converted SQL with configuration guidance.
```

### Example

**Before** (Synapse):

```sql
CREATE EXTERNAL DATA SOURCE [AzureDataLakeStore]
WITH
(
    TYPE = HADOOP,
    LOCATION = 'abfss://raw@mystorageaccount.dfs.core.windows.net'
);

CREATE EXTERNAL FILE FORMAT [ParquetFileFormat]
WITH
(
    FORMAT_TYPE = PARQUET,
    DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'
);

CREATE EXTERNAL TABLE [staging].[ext_CustomerRaw]
(
    [CustomerID]    INT,
    [FullName]      NVARCHAR(200),
    [Email]         NVARCHAR(256),
    [LoadDate]      DATE
)
WITH
(
    LOCATION = '/customers/current/',
    DATA_SOURCE = [AzureDataLakeStore],
    FILE_FORMAT = [ParquetFileFormat]
);
```

**After** (Fabric):

```sql
-- =====================================================================
-- FABRIC MIGRATION: External Data Source and File Format are replaced
-- by Lakehouse shortcuts in Microsoft Fabric.
--
-- Setup steps:
-- 1. Create a Lakehouse shortcut pointing to:
--    abfss://raw@mystorageaccount.dfs.core.windows.net/customers/current/
-- 2. The shortcut will expose Parquet files as a managed table.
-- 3. Query the shortcut table directly or use OPENROWSET for ad-hoc access.
-- =====================================================================

-- Option A: Query via Lakehouse shortcut (preferred for regular access)
SELECT
    [CustomerID],
    [FullName],
    [Email],
    [LoadDate]
FROM [LakehouseName].[dbo].[ext_CustomerRaw];

-- Option B: Ad-hoc query via OPENROWSET
SELECT
    [CustomerID],
    [FullName],
    [Email],
    [LoadDate]
FROM OPENROWSET(
    BULK 'https://onelake.dfs.fabric.microsoft.com/<workspace>/<lakehouse>/Files/customers/current/*.parquet',
    FORMAT = 'PARQUET'
) AS [result];
```

### Expected Outcome

The PolyBase external table infrastructure is replaced with Fabric-native Lakehouse shortcuts or OPENROWSET queries. The data engineering team has clear instructions for configuring the shortcut in the Fabric workspace, and downstream queries continue to access the same underlying data in Azure Data Lake Storage through OneLake.

### Related Prompts

[XDBREF-001](#xdbref001), [CTAS-001](#ctas001)

---

## CTAS-001: CTAS Statement Conversion

**Category:** DDL Compatibility
**Severity:** ðŸŸ¡ Medium
**Frequency:** ðŸ”· High
**Tags:** `CTAS` `CREATE TABLE AS SELECT` `distribution` `ETL` `staging` `transformation` `DDL`

### Description

Azure Synapse dedicated SQL pools commonly use CREATE TABLE AS SELECT (CTAS) with distribution and index options in the WITH clause for efficient data movement and transformation. Microsoft Fabric Warehouse supports CTAS but does not accept distribution or index hints in the WITH block. All CTAS statements must have their WITH clauses cleaned to remove Synapse-specific options.

### When to Use

Apply when the assessment processor identifies CTAS statements containing WITH (DISTRIBUTION = ...) or WITH (CLUSTERED COLUMNSTORE INDEX) clauses. CTAS is heavily used in ETL patterns for staging, transformation, and table rebuilds, so this conversion affects a significant portion of stored procedures and scripts.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following CREATE TABLE AS SELECT (CTAS) statement from an Azure Synapse dedicated SQL pool. Remove the WITH clause containing DISTRIBUTION and/or CLUSTERED COLUMNSTORE INDEX options. Keep the CREATE TABLE ... AS SELECT structure intact with all column references and transformations in the SELECT statement preserved exactly. If the WITH clause only contained Synapse-specific options, remove it entirely. Return only the cleaned SQL statement.
```

### Example

**Before** (Synapse):

```sql
CREATE TABLE [staging].[FactSales_Transformed]
WITH
(
    DISTRIBUTION = HASH([SalesKey]),
    CLUSTERED COLUMNSTORE INDEX
)
AS
SELECT
    s.[SalesKey],
    s.[OrderDateKey],
    s.[CustomerKey],
    s.[ProductKey],
    s.[Quantity],
    s.[UnitPrice],
    s.[Quantity] * s.[UnitPrice]  AS [TotalAmount],
    GETDATE()                     AS [ETLLoadDate]
FROM [raw].[FactSales] s
WHERE s.[OrderDateKey] >= 20230101;
```

**After** (Fabric):

```sql
CREATE TABLE [staging].[FactSales_Transformed]
AS
SELECT
    s.[SalesKey],
    s.[OrderDateKey],
    s.[CustomerKey],
    s.[ProductKey],
    s.[Quantity],
    s.[UnitPrice],
    s.[Quantity] * s.[UnitPrice]  AS [TotalAmount],
    GETDATE()                     AS [ETLLoadDate]
FROM [raw].[FactSales] s
WHERE s.[OrderDateKey] >= 20230101;
```

### Expected Outcome

The CTAS statement executes successfully in Fabric Warehouse. The table is created with Fabric-managed distribution and default clustered columnstore storage, and the data transformation logic in the SELECT statement is preserved without modification.

### Related Prompts

[DIST-001](#dist001), [CCI-001](#cci001)

---

## WLM-001: Workload Management Removal

**Category:** Resource Management
**Severity:** ðŸŸ¢ Low
**Frequency:** ðŸ”¶ Medium
**Tags:** `workload management` `resource class` `classifier` `capacity` `concurrency` `admin` `infrastructure`

### Description

Azure Synapse dedicated SQL pools use workload classifiers, workload groups, and resource classes to manage query concurrency and resource allocation. Microsoft Fabric uses a completely different capacity-based resource management model. All workload management DDL statements must be removed or commented out, as they have no equivalent in Fabric.

### When to Use

Apply when the assessment processor identifies CREATE WORKLOAD GROUP, CREATE WORKLOAD CLASSIFIER, ALTER WORKLOAD GROUP, or resource class assignment statements. These are typically found in administrative scripts rather than application code. They should be addressed during the infrastructure migration phase and replaced with Fabric capacity management configuration.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following workload management statements from an Azure Synapse dedicated SQL pool. Comment out all workload management DDL including CREATE WORKLOAD GROUP, CREATE WORKLOAD CLASSIFIER, ALTER WORKLOAD GROUP, and any sp_addrolemember calls for resource classes (e.g., staticrc20, largerc). Add a header comment block explaining that Fabric uses capacity-based resource management instead of workload classifiers and groups, and provide a brief note on the Fabric equivalent approach. Preserve the original code as commented-out lines for reference. Return the modified script.
```

### Example

**Before** (Synapse):

```sql
-- Synapse Workload Management Configuration
CREATE WORKLOAD GROUP [ETLProcessing]
WITH
(
    MIN_PERCENTAGE_RESOURCE = 25,
    CAP_PERCENTAGE_RESOURCE = 75,
    REQUEST_MIN_RESOURCE_GRANT_PERCENT = 5,
    REQUEST_MAX_RESOURCE_GRANT_PERCENT = 25
);

CREATE WORKLOAD CLASSIFIER [ETLClassifier]
WITH
(
    WORKLOAD_GROUP = 'ETLProcessing',
    MEMBERNAME = 'ETLServiceAccount',
    IMPORTANCE = HIGH
);

EXEC sp_addrolemember 'largerc', 'ETLServiceAccount';
```

**After** (Fabric):

```sql
-- =====================================================================
-- FABRIC MIGRATION: Workload management is not supported in Fabric.
-- Fabric uses capacity-based resource management:
--   - Capacity SKU determines total compute resources (F2, F4, F8, etc.)
--   - Smoothing and throttling are handled automatically by the engine
--   - Use Fabric Capacity Metrics app to monitor resource utilization
--   - Configure capacity settings in the Fabric Admin Portal
-- =====================================================================

-- REMOVED: Synapse workload group (no Fabric equivalent)
-- CREATE WORKLOAD GROUP [ETLProcessing]
-- WITH
-- (
--     MIN_PERCENTAGE_RESOURCE = 25,
--     CAP_PERCENTAGE_RESOURCE = 75,
--     REQUEST_MIN_RESOURCE_GRANT_PERCENT = 5,
--     REQUEST_MAX_RESOURCE_GRANT_PERCENT = 25
-- );

-- REMOVED: Synapse workload classifier (no Fabric equivalent)
-- CREATE WORKLOAD CLASSIFIER [ETLClassifier]
-- WITH
-- (
--     WORKLOAD_GROUP = 'ETLProcessing',
--     MEMBERNAME = 'ETLServiceAccount',
--     IMPORTANCE = HIGH
-- );

-- REMOVED: Resource class assignment (no Fabric equivalent)
-- EXEC sp_addrolemember 'largerc', 'ETLServiceAccount';
```

### Expected Outcome

All workload management DDL is cleanly commented out with clear documentation explaining the Fabric capacity management model. The migration team can review the original resource allocation strategy and map it to appropriate Fabric capacity SKU sizing decisions.

### Related Prompts

[STATS-001](#stats001)

---

## XDBREF-001: Cross-Database Reference Resolution

**Category:** Query Compatibility
**Severity:** ðŸ”´ Critical
**Frequency:** ðŸ”¶ Medium
**Tags:** `cross-database` `three-part name` `shortcut` `stored procedure` `workspace` `dependency`

### Description

Azure Synapse dedicated SQL pools support three-part naming ([database].[schema].[object]) for cross-database queries within the same logical server. Microsoft Fabric Warehouse does not support cross-database queries using three-part names. References must be resolved using Fabric Lakehouse shortcuts, warehouse cross-references within the same workspace, or by consolidating objects into a single warehouse.

### When to Use

Apply when the assessment processor identifies three-part name references in stored procedures, views, or ad-hoc queries. This is a critical issue because unresolved cross-database references cause immediate runtime failures. Coordinate with the data architecture team to establish the Fabric workspace and shortcut strategy before converting these references.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following SQL query or stored procedure from an Azure Synapse environment that contains cross-database references using three-part naming ([database].[schema].[object]). Convert all three-part references to two-part references ([schema].[object]) compatible with Fabric Warehouse. For each cross-database reference found, add a comment explaining that a Fabric Lakehouse shortcut or warehouse cross-reference must be configured to make the referenced object accessible. List all external database dependencies discovered. Return the converted SQL and the dependency list.
```

### Example

**Before** (Synapse):

```sql
CREATE PROCEDURE [dbo].[usp_LoadCustomerDimension]
AS
BEGIN
    INSERT INTO [dbo].[DimCustomer]
    (
        [CustomerKey], [CustomerName], [Email],
        [Region], [Segment]
    )
    SELECT
        c.[CustomerID],
        c.[FullName],
        c.[EmailAddress],
        g.[RegionName],
        s.[SegmentName]
    FROM [StagingDB].[dbo].[Customer] c
    INNER JOIN [ReferenceDB].[lookup].[Geography] g
        ON c.[GeoID] = g.[GeoID]
    INNER JOIN [ReferenceDB].[lookup].[Segment] s
        ON c.[SegmentID] = s.[SegmentID];
END;
```

**After** (Fabric):

```sql
-- FABRIC MIGRATION: Cross-database references resolved.
-- Dependencies requiring Lakehouse shortcuts or warehouse cross-references:
--   1. [StagingDB].[dbo].[Customer]       -> Configure shortcut to StagingDB
--   2. [ReferenceDB].[lookup].[Geography]  -> Configure shortcut to ReferenceDB
--   3. [ReferenceDB].[lookup].[Segment]    -> Configure shortcut to ReferenceDB
CREATE PROCEDURE [dbo].[usp_LoadCustomerDimension]
AS
BEGIN
    INSERT INTO [dbo].[DimCustomer]
    (
        [CustomerKey], [CustomerName], [Email],
        [Region], [Segment]
    )
    SELECT
        c.[CustomerID],
        c.[FullName],
        c.[EmailAddress],
        g.[RegionName],
        s.[SegmentName]
    FROM [dbo].[Customer] c
    INNER JOIN [lookup].[Geography] g
        ON c.[GeoID] = g.[GeoID]
    INNER JOIN [lookup].[Segment] s
        ON c.[SegmentID] = s.[SegmentID];
END;
```

### Expected Outcome

All three-part naming references are converted to two-part references that work in Fabric Warehouse. The migration team receives a complete list of external database dependencies that must be resolved through Lakehouse shortcuts or object consolidation before the procedure can execute successfully.

### Related Prompts

[EXTBL-001](#extbl001)

---

## UNICODE-001: Unicode String Normalization

**Category:** Data Type
**Severity:** ðŸŸ¡ Medium
**Frequency:** ðŸ”¹ Low
**Tags:** `VARCHAR` `NVARCHAR` `Unicode` `collation` `UTF-8` `encoding` `international` `data type`

### Description

Azure Synapse dedicated SQL pools allow VARCHAR columns to store non-Unicode data with various collations. Microsoft Fabric Warehouse uses UTF-8 as the default encoding and handles Unicode differently. Columns that store international characters, special symbols, or multi-byte data using VARCHAR may need to be converted to NVARCHAR to ensure data integrity, and explicit collation specifications may need adjustment for Fabric compatibility.

### When to Use

Apply when the assessment processor identifies VARCHAR columns that may contain Unicode data, or when data validation tests reveal character encoding issues after initial migration. Also apply when explicit collation specifications reference Synapse-specific collation names that are not available in Fabric.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following CREATE TABLE statement from an Azure Synapse dedicated SQL pool. Identify any VARCHAR columns that may store Unicode or international character data based on their column names (e.g., Name, Description, Address, City, Country) and convert them to NVARCHAR with the same length. If any explicit COLLATE clauses reference Synapse-specific collations, replace them with a Fabric-compatible collation (Latin1_General_100_BIN2_UTF8 for case-sensitive or Latin1_General_100_CI_AS_SC_UTF8 for case-insensitive). Add a comment listing the columns that were changed and why. Return the modified DDL.
```

### Example

**Before** (Synapse):

```sql
CREATE TABLE [dbo].[DimStore]
(
    [StoreKey]        INT            NOT NULL,
    [StoreName]       VARCHAR(200)   COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL,
    [Address]         VARCHAR(500)   NULL,
    [City]            VARCHAR(100)   NOT NULL,
    [Country]         VARCHAR(100)   NOT NULL,
    [PostalCode]      VARCHAR(20)    NOT NULL,
    [StoreCode]       VARCHAR(10)    NOT NULL,
    [IsActive]        BIT            NOT NULL
);
```

**After** (Fabric):

```sql
-- FABRIC MIGRATION: Converted VARCHAR to NVARCHAR for columns that may
-- contain international characters: StoreName, Address, City, Country.
-- Updated collation from SQL_Latin1_General_CP1_CI_AS to
-- Latin1_General_100_CI_AS_SC_UTF8 for Fabric UTF-8 compatibility.
-- StoreCode and PostalCode retained as VARCHAR (ASCII-only content).
CREATE TABLE [dbo].[DimStore]
(
    [StoreKey]        INT              NOT NULL,
    [StoreName]       NVARCHAR(200)    COLLATE Latin1_General_100_CI_AS_SC_UTF8 NOT NULL,
    [Address]         NVARCHAR(500)    NULL,
    [City]            NVARCHAR(100)    NOT NULL,
    [Country]         NVARCHAR(100)    NOT NULL,
    [PostalCode]      VARCHAR(20)      NOT NULL,
    [StoreCode]       VARCHAR(10)      NOT NULL,
    [IsActive]        BIT              NOT NULL
);
```

### Expected Outcome

String columns that store international character data are properly typed as NVARCHAR with Fabric-compatible collation. Data integrity is preserved during migration for all Unicode content, while ASCII-only columns remain as VARCHAR for storage efficiency.

### Related Prompts

[DTYPE-001](#dtype001)

---

## DTYPE-001: Deprecated Data Type Replacement

**Category:** Data Type
**Severity:** ðŸŸ¡ Medium
**Frequency:** ðŸ”¶ Medium
**Tags:** `MONEY` `SMALLMONEY` `DATETIME` `SMALLDATETIME` `DATETIME2` `DECIMAL` `data type` `deprecated`

### Description

Azure Synapse dedicated SQL pools support legacy SQL Server data types such as MONEY, SMALLMONEY, SMALLDATETIME, TINYINT (in some contexts), and DATETIME. While some of these work in Fabric, best practice for migration is to replace them with modern, portable equivalents: DECIMAL(19,4) for MONEY, DECIMAL(10,4) for SMALLMONEY, DATETIME2 for SMALLDATETIME and DATETIME. This ensures consistency and avoids subtle precision or range differences.

### When to Use

Apply when the assessment processor identifies columns using MONEY, SMALLMONEY, SMALLDATETIME, or DATETIME data types. This is a preventive conversion that reduces the risk of data precision issues and ensures forward compatibility with Fabric's evolving type system.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following CREATE TABLE statement from an Azure Synapse dedicated SQL pool. Replace deprecated or legacy data types with their modern equivalents: convert MONEY to DECIMAL(19,4), SMALLMONEY to DECIMAL(10,4), SMALLDATETIME to DATETIME2(0), and DATETIME to DATETIME2(3). Add a comment at the top listing each column that was changed and the type mapping applied. Preserve all column names, NULL/NOT NULL specifications, and DEFAULT constraints exactly as they are. Return the modified DDL.
```

### Example

**Before** (Synapse):

```sql
CREATE TABLE [dbo].[FactTransaction]
(
    [TransactionKey]  BIGINT          NOT NULL,
    [TransactionDate] DATETIME        NOT NULL,
    [PostingDate]     SMALLDATETIME   NOT NULL,
    [Amount]          MONEY           NOT NULL,
    [Tax]             SMALLMONEY      NOT NULL,
    [Discount]        MONEY           NULL DEFAULT 0,
    [CustomerKey]     INT             NOT NULL,
    [Description]     NVARCHAR(500)   NULL
);
```

**After** (Fabric):

```sql
-- FABRIC MIGRATION: Deprecated data type replacements applied:
--   [TransactionDate]  DATETIME      -> DATETIME2(3)
--   [PostingDate]      SMALLDATETIME -> DATETIME2(0)
--   [Amount]           MONEY         -> DECIMAL(19,4)
--   [Tax]              SMALLMONEY    -> DECIMAL(10,4)
--   [Discount]         MONEY         -> DECIMAL(19,4)
CREATE TABLE [dbo].[FactTransaction]
(
    [TransactionKey]  BIGINT          NOT NULL,
    [TransactionDate] DATETIME2(3)    NOT NULL,
    [PostingDate]     DATETIME2(0)    NOT NULL,
    [Amount]          DECIMAL(19,4)   NOT NULL,
    [Tax]             DECIMAL(10,4)   NOT NULL,
    [Discount]        DECIMAL(19,4)   NULL DEFAULT 0,
    [CustomerKey]     INT             NOT NULL,
    [Description]     NVARCHAR(500)   NULL
);
```

### Expected Outcome

All deprecated data types are replaced with modern equivalents that are fully supported in Fabric Warehouse. Data precision and range are preserved through appropriate type mappings, and the migration team has a clear record of every type change applied.

### Related Prompts

[UNICODE-001](#unicode001), [IDENT-001](#ident001)

---

## PART-001: Partition Scheme Conversion

**Category:** DDL Compatibility
**Severity:** ðŸŸ  High
**Frequency:** ðŸ”¹ Low
**Tags:** `partition` `PARTITION FUNCTION` `PARTITION SCHEME` `Delta` `Lakehouse` `Spark` `DDL`

### Description

Azure Synapse dedicated SQL pools support PARTITION FUNCTION and PARTITION SCHEME syntax for range-based table partitioning. Microsoft Fabric Warehouse does not support this T-SQL partitioning syntax. For Fabric Warehouse tables, partitioning is not directly user-configurable through DDL. For Lakehouse tables (Delta format), file-based partitioning can be configured through Spark or pipeline definitions. Partition functions and schemes must be removed from DDL scripts.

### When to Use

Apply when the assessment processor identifies CREATE PARTITION FUNCTION, CREATE PARTITION SCHEME, or CREATE TABLE statements with ON [partition_scheme] clauses. This typically affects large fact tables partitioned by date. Coordinate with the data architecture team to determine whether Lakehouse Delta partitioning is needed as a replacement.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following DDL statements from an Azure Synapse dedicated SQL pool that define partition functions, partition schemes, and tables using those partitions. Remove the CREATE PARTITION FUNCTION and CREATE PARTITION SCHEME statements. Remove the ON [partition_scheme](column) clause from the CREATE TABLE statement. Add a comment block explaining the Fabric partitioning alternatives: (1) Fabric Warehouse tables do not support user-defined partitioning, (2) For Lakehouse tables in Delta format, partitioning can be configured via Spark using partitionBy, (3) Include the original partition boundaries for reference if the team needs to implement Delta partitioning. Return the cleaned DDL with advisory comments.
```

### Example

**Before** (Synapse):

```sql
CREATE PARTITION FUNCTION [pf_OrderDate](INT)
AS RANGE RIGHT FOR VALUES
(
    20220101, 20220201, 20220301, 20220401,
    20220501, 20220601, 20220701, 20220801,
    20220901, 20221001, 20221101, 20221201,
    20230101
);

CREATE PARTITION SCHEME [ps_OrderDate]
AS PARTITION [pf_OrderDate]
ALL TO ([PRIMARY]);

CREATE TABLE [dbo].[FactOrders]
(
    [OrderKey]        BIGINT         NOT NULL,
    [OrderDateKey]    INT            NOT NULL,
    [CustomerKey]     INT            NOT NULL,
    [TotalAmount]     DECIMAL(18,2)  NOT NULL
)
ON [ps_OrderDate]([OrderDateKey]);
```

**After** (Fabric):

```sql
-- =====================================================================
-- FABRIC MIGRATION: Partition function and scheme removed.
-- Fabric Warehouse does not support T-SQL partitioning syntax.
--
-- Alternatives:
--   1. Fabric Warehouse: No user-defined partitioning (engine optimizes internally)
--   2. Fabric Lakehouse (Delta): Use Spark partitionBy('OrderDateKey') for
--      file-based partitioning during data writes
--
-- Original partition boundaries (for Delta partitioning reference):
--   Monthly by OrderDateKey: 20220101 through 20230101
-- =====================================================================

CREATE TABLE [dbo].[FactOrders]
(
    [OrderKey]        BIGINT         NOT NULL,
    [OrderDateKey]    INT            NOT NULL,
    [CustomerKey]     INT            NOT NULL,
    [TotalAmount]     DECIMAL(18,2)  NOT NULL
);
```

### Expected Outcome

Partition functions, partition schemes, and ON [scheme] clauses are removed from the DDL. The CREATE TABLE statement deploys successfully in Fabric Warehouse. The original partition strategy is documented in comments for reference when configuring Lakehouse Delta partitioning if needed.

### Related Prompts

[DIST-001](#dist001), [CTAS-001](#ctas001)

---

## STATS-001: Statistics Creation Syntax Update

**Category:** Performance
**Severity:** ðŸŸ¢ Low
**Frequency:** ðŸ”· High
**Tags:** `statistics` `FULLSCAN` `SAMPLE` `NORECOMPUTE` `auto-stats` `performance` `query optimizer`

### Description

Azure Synapse dedicated SQL pools require manual creation and maintenance of statistics using CREATE STATISTICS with options like FULLSCAN, SAMPLE PERCENT, and NORECOMPUTE. Microsoft Fabric Warehouse provides automatic statistics management. While CREATE STATISTICS is still supported in Fabric, the FULLSCAN and SAMPLE options are not needed and NORECOMPUTE should be removed to allow Fabric's auto-stats engine to maintain statistics. Explicit statistics creation scripts can be simplified or removed entirely.

### When to Use

Apply when the assessment processor identifies CREATE STATISTICS or UPDATE STATISTICS statements with Synapse-specific options. Also apply to stored procedures or maintenance scripts that contain statistics management logic. This is a lower-priority conversion but affects query performance tuning scripts across the codebase.

### Copilot Prompt

Copy the following prompt into your Copilot Chat along with the SQL code to transform:

```text
Analyze the following statistics management statements from an Azure Synapse dedicated SQL pool. Simplify CREATE STATISTICS statements by removing FULLSCAN, SAMPLE, and NORECOMPUTE options. Comment out UPDATE STATISTICS statements and any statistics maintenance stored procedures, as Fabric handles statistics updates automatically. Add a comment explaining that Fabric Warehouse provides automatic statistics creation and maintenance, and manual statistics management is typically unnecessary. Preserve the original code as comments for reference. Return the simplified script.
```

### Example

**Before** (Synapse):

```sql
-- Statistics maintenance script
CREATE STATISTICS [stat_FactSales_OrderDateKey]
    ON [dbo].[FactSales]([OrderDateKey])
    WITH FULLSCAN;

CREATE STATISTICS [stat_FactSales_CustomerKey]
    ON [dbo].[FactSales]([CustomerKey])
    WITH SAMPLE 50 PERCENT;

CREATE STATISTICS [stat_FactSales_Composite]
    ON [dbo].[FactSales]([OrderDateKey], [ProductKey])
    WITH FULLSCAN, NORECOMPUTE;

UPDATE STATISTICS [dbo].[FactSales] WITH FULLSCAN;
```

**After** (Fabric):

```sql
-- =====================================================================
-- FABRIC MIGRATION: Statistics management simplified.
-- Fabric Warehouse provides automatic statistics creation and maintenance.
-- Manual statistics management is typically unnecessary.
-- The auto-stats engine creates and updates statistics as needed during
-- query compilation. Remove or simplify these statements for Fabric.
-- =====================================================================

-- Simplified: Removed FULLSCAN option (Fabric manages sample strategy)
CREATE STATISTICS [stat_FactSales_OrderDateKey]
    ON [dbo].[FactSales]([OrderDateKey]);

-- Simplified: Removed SAMPLE option (Fabric manages sample strategy)
CREATE STATISTICS [stat_FactSales_CustomerKey]
    ON [dbo].[FactSales]([CustomerKey]);

-- Simplified: Removed FULLSCAN and NORECOMPUTE (allow Fabric auto-update)
CREATE STATISTICS [stat_FactSales_Composite]
    ON [dbo].[FactSales]([OrderDateKey], [ProductKey]);

-- REMOVED: Manual UPDATE STATISTICS (Fabric handles automatically)
-- UPDATE STATISTICS [dbo].[FactSales] WITH FULLSCAN;
```

### Expected Outcome

Statistics creation statements are simplified to Fabric-compatible syntax without Synapse-specific options. Manual UPDATE STATISTICS calls are removed, allowing Fabric's automatic statistics engine to manage statistics maintenance. Query optimizer continues to have access to the same statistical information through Fabric's auto-stats feature.

### Related Prompts

[MATVIEW-001](#matview001), [WLM-001](#wlm001)

---

## Adding New Prompts

1. Edit `prompts.json` and add a new entry following the schema in `prompts.schema.json`.
2. Run `python validate.py` to verify the new entry passes all checks.
3. Run `python render_catalog.py` to regenerate this catalog.

---

*Generated by the DMTSP Fabric Migration Assistant - Copilot Prompt Library*
